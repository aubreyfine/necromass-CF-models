# - If you want to FORCE calibration through zero, change the model to:
#     lm(npoc_area ~ 0 + cal_conc, data = cal)
#   and similarly for TNb, then re-derive concentrations accordingly.
# - You can narrow which rows belong to the initial calibration by adding guards,
#   e.g., filter(memo %in% c("h2o","0.1ppm","1ppm","10ppm")) within 'cal_block'
#   if your file ever has other RunIn entries at the top.
# --- NPOC & TNb analysis from Shimadzu-style CSV ---
# Packages
suppressPackageStartupMessages({
library(tidyverse)
library(janitor)
library(stringr)
})
setwd("C:/Users/xpf/OneDrive - Oak Ridge National Laboratory/DirectoryAKF/AFINE")
# === 1) Load ===
# Change this path if needed
infile <- "data/SET2.csv"
raw <- read_csv(infile, show_col_types = FALSE) %>%
clean_names()
# Quick sanity: standard Shimadzu-like column names after clean_names():
# no, hole_pos, name, memo, method, coefficients, npoc_vol_ml, dilut_factor,
# npoc_area, tnb_area, npoc_mg_l, tnb_mg_l, date_time
# === 2) Identify the initial calibration block ===
# We take rows from the start until the first non-RunIn "Name"
first_sample_row <- which(raw$name != "RunIn")[1]
cal_block <- raw %>% slice(1:(first_sample_row - 1))
# Map memo → calibration concentration (ppm == mg/L)
memo_to_conc <- function(x) {
x <- tolower(x %||% "")
case_when(
str_detect(x, "10ppm") ~ 10,
str_detect(x, "0\\.1ppm") ~ 0.1,
str_detect(x, "(^|\\D)1ppm(\\D|$)") ~ 1,
str_detect(x, "h2o|water") ~ 0,
TRUE ~ NA_real_
)
}
cal <- cal_block %>%
mutate(
cal_conc = memo_to_conc(memo)
) %>%
# forward-fill concentration across replicate injections
tidyr::fill(cal_conc, .direction = "down")
# === 3) Fit linear calibrations (Area -> mg/L) ===
# We fit y = a + b * x with x = concentration, y = Area.
# Later we invert to get concentration from Area: x = (y - a)/b
# Calibration range (in mg/L)
cal_min <- min(cal$cal_conc, na.rm = TRUE)
cal_max <- max(cal$cal_conc, na.rm = TRUE)
cat("\nCalibration range (mg/L):", cal_min, "to", cal_max, "\n")
# Map memo → calibration concentration
memo_to_conc <- function(x) {
x <- tolower(ifelse(is.na(x), "", x))
x <- gsub("\\s+", "", x)  # handle "0.1 ppm" vs "0.1ppm"
dplyr::case_when(
grepl("10ppm", x) ~ 10,
grepl("0\\.1ppm", x) ~ 0.1,
grepl("(^|\\D)1ppm(\\D|$)", x) ~ 1,
grepl("h2o|water|0ppm|blank", x) ~ 0,
TRUE ~ NA_real_
)
}
# Fit linear calibration using a STRING column name for x
fit_lm <- function(df, area_col, conc_col = "cal_conc") {
stopifnot(area_col %in% names(df), conc_col %in% names(df))
stats::lm(reformulate(termlabels = conc_col, response = area_col), data = df)
}
lm_npoc <- fit_lm(cal, "npoc_area")
lm_tnb  <- fit_lm(cal, "t_nb_area")
coef_npoc <- coef(lm_npoc) # (Intercept), cal_conc
coef_tnb  <- coef(lm_tnb)
# Helper to invert the calibration (Area -> mg/L)
area_to_conc <- function(area, intercept, slope) {
(area - intercept) / slope
}
# === 4) Compute concentrations for all rows (with dilution if present) ===
data_proc <- raw %>%
mutate(
# make dilution numeric, default 1
dil_factor = suppressWarnings(as.numeric(dilut_factor)),
dil_factor = if_else(is.na(dil_factor), 1, dil_factor),
# raw concentrations from instrument response (before dilution factor)
npoc_mg_l_calc_raw = area_to_conc(npoc_area, coef_npoc[1], coef_npoc[2]),
tnb_mg_l_calc_raw  = area_to_conc(t_nb_area,  coef_tnb[1],  coef_tnb[2]),
# apply dilution correction (final conc in original sample)
npoc_mg_l_calc = npoc_mg_l_calc_raw * dil_factor,
tnb_mg_l_calc  = tnb_mg_l_calc_raw  * dil_factor,
# ---- FLAGS: outside calibration range (based on raw concentration) ----
npoc_oob = npoc_mg_l_calc_raw < cal_min | npoc_mg_l_calc_raw > cal_max,
tnb_oob  = tnb_mg_l_calc_raw  < cal_min | tnb_mg_l_calc_raw  > cal_max
)
#RSD = (SD / Mean) * 100
# === 5) Summarize samples (exclude RunIn calibration injections) ===
samples_only <- data_proc %>%
filter(name != "RunIn")
high_rsd_threshold <- 10  # percent cutoff (change if needed)
sample_summary <- samples_only %>%
group_by(name) %>%
summarise(
n = n(),
# Core stats
npoc_mean_mg_l = mean(npoc_mg_l_calc, na.rm = TRUE),
npoc_sd_mg_l   = sd(npoc_mg_l_calc, na.rm = TRUE),
tnb_mean_mg_l  = mean(tnb_mg_l_calc,  na.rm = TRUE),
tnb_sd_mg_l    = sd(tnb_mg_l_calc,   na.rm = TRUE),
# %RSD
npoc_rsd = 100 * npoc_sd_mg_l / npoc_mean_mg_l,
tnb_rsd  = 100 * tnb_sd_mg_l  / tnb_mean_mg_l,
# Flags
npoc_any_oob = any(npoc_oob, na.rm = TRUE),
tnb_any_oob  = any(tnb_oob,  na.rm = TRUE),
npoc_high_sd = npoc_rsd > high_rsd_threshold,
tnb_high_sd  = tnb_rsd  > high_rsd_threshold,
.groups = "drop"
) %>%
arrange(name)
# === 6) QC: model fit stats & check standards (end-of-run) ===
qc_fit <- tibble(
analyte = c("NPOC", "TNb"),
intercept = c(unname(coef_npoc[1]), unname(coef_tnb[1])),
slope     = c(unname(coef_npoc[2]), unname(coef_tnb[2])),
r_squared = c(summary(lm_npoc)$r.squared, summary(lm_tnb)$r.squared)
)
# End-of-run check standards: look for RunIn rows AFTER the first sample
end_checks <- raw %>%
slice(first_sample_row:n()) %>%
filter(name == "RunIn") %>%
mutate(
target = memo_to_conc(memo),
npoc_found = area_to_conc(npoc_area, coef_npoc[1], coef_npoc[2]),
tnb_found  = area_to_conc(t_nb_area,  coef_tnb[1],  coef_tnb[2]),
npoc_recov_percent = 100 * npoc_found / target,
tnb_recov_percent  = 100 * tnb_found / target
) %>%
# Keep only rows that have a defined calibration target (e.g., 0, 0.1, 1, 10)
filter(!is.na(target)) %>%
select(no, memo, target, npoc_found, npoc_recov_percent, tnb_found, tnb_recov_percent)
# === 7) Plots (optional) ===
# Calibration plots with fitted line and residuals
plot_cal <- function(df, area_col, title) {
ggplot(df, aes(x = cal_conc, y = .data[[area_col]])) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(x = "Concentration (mg/L)", y = "Area", title = title) +
theme_minimal()
}
p_cal_npoc <- plot_cal(cal, "npoc_area", "Calibration: NPOC")
p_cal_tnb  <- plot_cal(cal, "tnb_area",  "Calibration: TNb")
# Print key outputs
cat("\n=== Calibration (fit) ===\n")
print(qc_fit)
cat("\n=== End-of-run check standards (recoveries) ===\n")
print(end_checks)
cat("\n=== Sample summary (mean ± sd) ===\n")
print(sample_summary)
# If running interactively, you can also print plots:
# print(p_cal_npoc); print(p_cal_tnb)
# --- 8) Optional: write results ---
# Use the same title as the input CSV for the output
out_name <- paste0(tools::file_path_sans_ext(basename(infile)), "_summary.csv")
# Save to the same folder as the input
write_csv(sample_summary, out_name)
cat("\n✅ Saved summarized results as:", out_name, "\n")
# ggsave("cal_npoc.png", p_cal_npoc, width = 6, height = 4, dpi = 300)
# ggsave("cal_tnb.png",  p_cal_tnb,  width = 6, height = 4, dpi = 300)
# Notes:
# - If you performed additional dilutions per sample and they are NOT recorded in 'dilut_factor',
#   add them there or merge a lookup table and recalc. The code above will multiply by that factor.
# - If you want to FORCE calibration through zero, change the model to:
#     lm(npoc_area ~ 0 + cal_conc, data = cal)
#   and similarly for TNb, then re-derive concentrations accordingly.
# - You can narrow which rows belong to the initial calibration by adding guards,
#   e.g., filter(memo %in% c("h2o","0.1ppm","1ppm","10ppm")) within 'cal_block'
#   if your file ever has other RunIn entries at the top.
# --- NPOC & TNb analysis from Shimadzu-style CSV ---
# Packages
suppressPackageStartupMessages({
library(tidyverse)
library(janitor)
library(stringr)
})
setwd("C:/Users/xpf/OneDrive - Oak Ridge National Laboratory/DirectoryAKF/AFINE")
# === 1) Load ===
# Change this path if needed
infile <- "data/SET1.csv"
raw <- read_csv(infile, show_col_types = FALSE) %>%
clean_names()
# Quick sanity: standard Shimadzu-like column names after clean_names():
# no, hole_pos, name, memo, method, coefficients, npoc_vol_ml, dilut_factor,
# npoc_area, tnb_area, npoc_mg_l, tnb_mg_l, date_time
# === 2) Identify the initial calibration block ===
# We take rows from the start until the first non-RunIn "Name"
first_sample_row <- which(raw$name != "RunIn")[1]
cal_block <- raw %>% slice(1:(first_sample_row - 1))
# Map memo → calibration concentration (ppm == mg/L)
memo_to_conc <- function(x) {
x <- tolower(x %||% "")
case_when(
str_detect(x, "10ppm") ~ 10,
str_detect(x, "0\\.1ppm") ~ 0.1,
str_detect(x, "(^|\\D)1ppm(\\D|$)") ~ 1,
str_detect(x, "h2o|water") ~ 0,
TRUE ~ NA_real_
)
}
cal <- cal_block %>%
mutate(
cal_conc = memo_to_conc(memo)
) %>%
# forward-fill concentration across replicate injections
tidyr::fill(cal_conc, .direction = "down")
# === 3) Fit linear calibrations (Area -> mg/L) ===
# We fit y = a + b * x with x = concentration, y = Area.
# Later we invert to get concentration from Area: x = (y - a)/b
# Calibration range (in mg/L)
cal_min <- min(cal$cal_conc, na.rm = TRUE)
cal_max <- max(cal$cal_conc, na.rm = TRUE)
cat("\nCalibration range (mg/L):", cal_min, "to", cal_max, "\n")
# Map memo → calibration concentration
memo_to_conc <- function(x) {
x <- tolower(ifelse(is.na(x), "", x))
x <- gsub("\\s+", "", x)  # handle "0.1 ppm" vs "0.1ppm"
dplyr::case_when(
grepl("10ppm", x) ~ 10,
grepl("0\\.1ppm", x) ~ 0.1,
grepl("(^|\\D)1ppm(\\D|$)", x) ~ 1,
grepl("h2o|water|0ppm|blank", x) ~ 0,
TRUE ~ NA_real_
)
}
# Fit linear calibration using a STRING column name for x
fit_lm <- function(df, area_col, conc_col = "cal_conc") {
stopifnot(area_col %in% names(df), conc_col %in% names(df))
stats::lm(reformulate(termlabels = conc_col, response = area_col), data = df)
}
lm_npoc <- fit_lm(cal, "npoc_area")
lm_tnb  <- fit_lm(cal, "t_nb_area")
coef_npoc <- coef(lm_npoc) # (Intercept), cal_conc
coef_tnb  <- coef(lm_tnb)
# Helper to invert the calibration (Area -> mg/L)
area_to_conc <- function(area, intercept, slope) {
(area - intercept) / slope
}
# === 4) Compute concentrations for all rows (with dilution if present) ===
data_proc <- raw %>%
mutate(
# make dilution numeric, default 1
dil_factor = suppressWarnings(as.numeric(dilut_factor)),
dil_factor = if_else(is.na(dil_factor), 1, dil_factor),
# raw concentrations from instrument response (before dilution factor)
npoc_mg_l_calc_raw = area_to_conc(npoc_area, coef_npoc[1], coef_npoc[2]),
tnb_mg_l_calc_raw  = area_to_conc(t_nb_area,  coef_tnb[1],  coef_tnb[2]),
# apply dilution correction (final conc in original sample)
npoc_mg_l_calc = npoc_mg_l_calc_raw * dil_factor,
tnb_mg_l_calc  = tnb_mg_l_calc_raw  * dil_factor,
# ---- FLAGS: outside calibration range (based on raw concentration) ----
npoc_oob = npoc_mg_l_calc_raw < cal_min | npoc_mg_l_calc_raw > cal_max,
tnb_oob  = tnb_mg_l_calc_raw  < cal_min | tnb_mg_l_calc_raw  > cal_max
)
#RSD = (SD / Mean) * 100
# === 5) Summarize samples (exclude RunIn calibration injections) ===
samples_only <- data_proc %>%
filter(name != "RunIn")
high_rsd_threshold <- 10  # percent cutoff (change if needed)
sample_summary <- samples_only %>%
group_by(name) %>%
summarise(
n = n(),
# Core stats
npoc_mean_mg_l = mean(npoc_mg_l_calc, na.rm = TRUE),
npoc_sd_mg_l   = sd(npoc_mg_l_calc, na.rm = TRUE),
tnb_mean_mg_l  = mean(tnb_mg_l_calc,  na.rm = TRUE),
tnb_sd_mg_l    = sd(tnb_mg_l_calc,   na.rm = TRUE),
# %RSD
npoc_rsd = 100 * npoc_sd_mg_l / npoc_mean_mg_l,
tnb_rsd  = 100 * tnb_sd_mg_l  / tnb_mean_mg_l,
# Flags
npoc_any_oob = any(npoc_oob, na.rm = TRUE),
tnb_any_oob  = any(tnb_oob,  na.rm = TRUE),
npoc_high_sd = npoc_rsd > high_rsd_threshold,
tnb_high_sd  = tnb_rsd  > high_rsd_threshold,
.groups = "drop"
) %>%
arrange(name)
# === 6) QC: model fit stats & check standards (end-of-run) ===
qc_fit <- tibble(
analyte = c("NPOC", "TNb"),
intercept = c(unname(coef_npoc[1]), unname(coef_tnb[1])),
slope     = c(unname(coef_npoc[2]), unname(coef_tnb[2])),
r_squared = c(summary(lm_npoc)$r.squared, summary(lm_tnb)$r.squared)
)
# End-of-run check standards: look for RunIn rows AFTER the first sample
end_checks <- raw %>%
slice(first_sample_row:n()) %>%
filter(name == "RunIn") %>%
mutate(
target = memo_to_conc(memo),
npoc_found = area_to_conc(npoc_area, coef_npoc[1], coef_npoc[2]),
tnb_found  = area_to_conc(t_nb_area,  coef_tnb[1],  coef_tnb[2]),
npoc_recov_percent = 100 * npoc_found / target,
tnb_recov_percent  = 100 * tnb_found / target
) %>%
# Keep only rows that have a defined calibration target (e.g., 0, 0.1, 1, 10)
filter(!is.na(target)) %>%
select(no, memo, target, npoc_found, npoc_recov_percent, tnb_found, tnb_recov_percent)
# === 7) Plots (optional) ===
# Calibration plots with fitted line and residuals
plot_cal <- function(df, area_col, title) {
ggplot(df, aes(x = cal_conc, y = .data[[area_col]])) +
geom_point() +
geom_smooth(method = "lm", se = FALSE) +
labs(x = "Concentration (mg/L)", y = "Area", title = title) +
theme_minimal()
}
p_cal_npoc <- plot_cal(cal, "npoc_area", "Calibration: NPOC")
p_cal_tnb  <- plot_cal(cal, "tnb_area",  "Calibration: TNb")
# Print key outputs
cat("\n=== Calibration (fit) ===\n")
print(qc_fit)
cat("\n=== End-of-run check standards (recoveries) ===\n")
print(end_checks)
cat("\n=== Sample summary (mean ± sd) ===\n")
print(sample_summary)
# If running interactively, you can also print plots:
# print(p_cal_npoc); print(p_cal_tnb)
# --- 8) Optional: write results ---
# Use the same title as the input CSV for the output
out_name <- paste0(tools::file_path_sans_ext(basename(infile)), "_summary.csv")
# Save to the same folder as the input
write_csv(sample_summary, out_name)
cat("\n✅ Saved summarized results as:", out_name, "\n")
# ggsave("cal_npoc.png", p_cal_npoc, width = 6, height = 4, dpi = 300)
# ggsave("cal_tnb.png",  p_cal_tnb,  width = 6, height = 4, dpi = 300)
# Notes:
# - If you performed additional dilutions per sample and they are NOT recorded in 'dilut_factor',
#   add them there or merge a lookup table and recalc. The code above will multiply by that factor.
# - If you want to FORCE calibration through zero, change the model to:
#     lm(npoc_area ~ 0 + cal_conc, data = cal)
#   and similarly for TNb, then re-derive concentrations accordingly.
# - You can narrow which rows belong to the initial calibration by adding guards,
#   e.g., filter(memo %in% c("h2o","0.1ppm","1ppm","10ppm")) within 'cal_block'
#   if your file ever has other RunIn entries at the top.
# ============================================================
# 01_setup.R — Common R setup for necromass-cf
# ============================================================
cat("\n=== necromass-cf: R setup ===\n")
options(
repos = c(CRAN = "https://cloud.r-project.org"),
dplyr.summarise.inform = FALSE
)
pkgs <- c(
"tidyverse",
"ggridges",
"patchwork",
"forcats",
"here"
)
# Load required packages (assumed installed via renv or manually)
missing <- pkgs[!vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)]
if (length(missing) > 0) {
warning("Missing packages (install via renv or install.packages): ",
paste(missing, collapse = ", "))
} else {
cat("Loaded packages:\n  ", paste(pkgs, collapse = ", "), "\n")
}
suppressPackageStartupMessages({
lapply(pkgs, require, character.only = TRUE)
})
# A consistent base theme for figures
theme_set(ggplot2::theme_minimal(base_size = 9))
cat("R version:\n")
print(R.version.string)
cat("=== setup complete ===\n")
# ============================================================
# Figure 2 – Variation in microbial amino-sugar content
# Inputs : data/bactMurA.csv, data/fungGlcN.csv
# Output : outputs/figures/Figure2.tiff
# ============================================================
options(scipen = 999)
suppressPackageStartupMessages({
library(tidyverse)
library(forcats)
library(ggridges)
library(patchwork)
library(here)
})
# ---- check project root ----
message("Project root: ", here::here())
# ---- paths ----
bact_file <- here::here("data", "bactMurA.csv")
fung_file <- here::here("data", "fungGlcN.csv")
outdir    <- here::here("outputs", "figures")
outfile   <- here::here(outdir, "Figure2.tiff")
if (!dir.exists(outdir)) dir.create(outdir, recursive = TRUE)
# ---- palettes and phyla ----
pal_gram <- c(GN = "#43BBAD", GP = "#414388FF")
gram_map <- c("Pseudomonadota" = "GN", "Firmicutes" = "GP", "Actinomycetota" = "GP")
phyl_A   <- c("Pseudomonadota","Firmicutes","Actinomycetota")
phyl_B   <- c("Ascomycota","Basidiomycota")
# ---- read data ----
bac <- readr::read_csv(bact_file, show_col_types = FALSE) %>%
dplyr::rename(
Phylum = tidyselect::any_of(c("Phylum","phylum","BacterialPhylum")),
MurA   = tidyselect::any_of(c("MurA","murA","MurA_mg_g_biomass"))
) %>%
dplyr::select(Phylum, MurA)
setwd('C:/Users/xpf/OneDrive - Oak Ridge National Laboratory/DirectoryAKF/Necromass/data_revision2025_SUBMISSION/NecromassCF')
getwd
getwd()
setwd("C:/Users/xpf/OneDrive - Oak Ridge National Laboratory/DirectoryAKF/Necromass/data_revision2025/SUBMISSION/NecromassCF")
# ============================================================
# 01_setup.R — Common R setup for necromass-cf
# ============================================================
cat("\n=== necromass-cf: R setup ===\n")
options(
repos = c(CRAN = "https://cloud.r-project.org"),
dplyr.summarise.inform = FALSE
)
pkgs <- c(
"tidyverse",
"ggridges",
"patchwork",
"forcats",
"here"
)
# Load required packages (assumed installed via renv or manually)
missing <- pkgs[!vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)]
if (length(missing) > 0) {
warning("Missing packages (install via renv or install.packages): ",
paste(missing, collapse = ", "))
} else {
cat("Loaded packages:\n  ", paste(pkgs, collapse = ", "), "\n")
}
suppressPackageStartupMessages({
lapply(pkgs, require, character.only = TRUE)
})
# A consistent base theme for figures
theme_set(ggplot2::theme_minimal(base_size = 9))
cat("R version:\n")
print(R.version.string)
cat("=== setup complete ===\n")
# ============================================================
# Figure 2 – Variation in microbial amino-sugar content
# Inputs : data/bactMurA.csv, data/fungGlcN.csv
# Output : outputs/figures/Figure2.tiff
# ============================================================
options(scipen = 999)
suppressPackageStartupMessages({
library(tidyverse)
library(forcats)
library(ggridges)
library(patchwork)
library(here)
})
# ---- check project root ----
message("Project root: ", here::here())
# ---- paths ----
bact_file <- here::here("data", "bactMurA.csv")
fung_file <- here::here("data", "fungGlcN.csv")
outdir    <- here::here("outputs", "figures")
outfile   <- here::here(outdir, "Figure2.tiff")
if (!dir.exists(outdir)) dir.create(outdir, recursive = TRUE)
# ---- palettes and phyla ----
pal_gram <- c(GN = "#43BBAD", GP = "#414388FF")
gram_map <- c("Pseudomonadota" = "GN", "Firmicutes" = "GP", "Actinomycetota" = "GP")
phyl_A   <- c("Pseudomonadota","Firmicutes","Actinomycetota")
phyl_B   <- c("Ascomycota","Basidiomycota")
# ---- read data ----
bac <- readr::read_csv(bact_file, show_col_types = FALSE) %>%
dplyr::rename(
Phylum = tidyselect::any_of(c("Phylum","phylum","BacterialPhylum")),
MurA   = tidyselect::any_of(c("MurA","murA","MurA_mg_g_biomass"))
) %>%
dplyr::select(Phylum, MurA)
getwd()
# ============================================================
# Figure 2 – Variation in microbial amino-sugar content
# Inputs : data/bactMurA.csv, data/fungGlcN.csv
# Output : outputs/figures/Figure2.tiff
# ============================================================
options(scipen = 999)
suppressPackageStartupMessages({
library(tidyverse)
library(forcats)
library(ggridges)
library(patchwork)
library(here)
})
# ---- check project root ----
message("Project root: ", here::here())
# ---- paths ----
bact_file <- here::here("data", "bactMurA.csv")
fung_file <- here::here("data", "fungGlcN.csv")
outdir    <- here::here("outputs", "figures")
outfile   <- here::here(outdir, "Figure2.tiff")
if (!dir.exists(outdir)) dir.create(outdir, recursive = TRUE)
# ---- palettes and phyla ----
pal_gram <- c(GN = "#43BBAD", GP = "#414388FF")
gram_map <- c("Pseudomonadota" = "GN", "Firmicutes" = "GP", "Actinomycetota" = "GP")
phyl_A   <- c("Pseudomonadota","Firmicutes","Actinomycetota")
phyl_B   <- c("Ascomycota","Basidiomycota")
# ---- read data ----
bac <- readr::read_csv(bact_file, show_col_types = FALSE) %>%
dplyr::rename(
Phylum = tidyselect::any_of(c("Phylum","phylum","BacterialPhylum")),
MurA   = tidyselect::any_of(c("MurA","murA","MurA_mg_g_biomass"))
) %>%
dplyr::select(Phylum, MurA)
here::here()
rprojroot::find_root(rprojroot::is_rstudio_project)
rprojroot::find_root_file(criterion = rprojroot::is_git_root)
here::i_am("NecromassCF_root.txt")
